{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d5a9625-b8db-4a9d-a749-4c5f1dd4a7ba",
      "metadata": {
        "id": "2d5a9625-b8db-4a9d-a749-4c5f1dd4a7ba",
        "outputId": "99e654f3-979d-4ba6-9f76-2344b6a8f68a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /home/uazam/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gzip\n",
        "import logging\n",
        "import random\n",
        "import sys\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "import tqdm\n",
        "\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "from datasets import  load_from_disk, Dataset, load_dataset\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, models\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from sentence_transformers.losses import DenoisingAutoEncoderLoss\n",
        "from sentence_transformers.similarity_functions import SimilarityFunction\n",
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b1447bc-4c43-4577-bc98-a7600d92971e",
      "metadata": {
        "id": "1b1447bc-4c43-4577-bc98-a7600d92971e",
        "outputId": "c697604b-5f24-4e38-f7f2-369826ac8147"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model_checkpoint = \"bert-base-uncased\"\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f984332-8fcd-4b9d-849b-128dc6df5de1",
      "metadata": {
        "id": "8f984332-8fcd-4b9d-849b-128dc6df5de1"
      },
      "outputs": [],
      "source": [
        "ds = load_dataset('UmarAzam/wikipedia_subsets',split='train')\n",
        "ds = ds.sort('hits',reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85181a1a-9408-454a-affe-76a4b4c53082",
      "metadata": {
        "id": "85181a1a-9408-454a-affe-76a4b4c53082"
      },
      "outputs": [],
      "source": [
        "max_token_length = tokenizer.model_max_length\n",
        "# split_overlap parameter defines how many segments the model's context window should split into. The training data will move one segment forwarch with each datapoint so that there's overlap in\n",
        "# the text to enable the model to learn contextual association in a moving window.\n",
        "split_overlap = 2\n",
        "token_stride = int(max_token_length / split_overlap)\n",
        "\n",
        "def generate_splits(item):\n",
        "  output = tokenizer(item['text'], return_offsets_mapping=True)\n",
        "  # Add mapping that provides indices for tokens to split text data evenly\n",
        "  item['offset_list'] =  [[offset_list[ind][1] for ind in range(0,len(offset_list),token_stride)] for offset_list in output['offset_mapping']]\n",
        "  return item\n",
        "\n",
        "def generate_sentences(item):\n",
        "  # offset_list = item['offset_list']\n",
        "  # text = item['text']\n",
        "  # sentences = [text[offset_list[ind]:offset_list[ind+2]] for ind in range(0,len(offset_list)-2)]\n",
        "  # return {'sentences' : sentences}\n",
        "  #\n",
        "  # For Batched code is as follows\n",
        "    offset_lists = item['offset_list']\n",
        "    texts = item['text']\n",
        "    sentences = []\n",
        "    for ind, offset_list in enumerate(offset_lists):\n",
        "      sentences += [texts[ind][offset_list[i]:offset_list[i+split_overlap]] for i in range(0,len(offset_list)-2)]\n",
        "    return {'text' : sentences}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a97eb4d9-c688-4ec6-862d-6dcda0663253",
      "metadata": {
        "id": "a97eb4d9-c688-4ec6-862d-6dcda0663253"
      },
      "outputs": [],
      "source": [
        "# ds_s = ds.select(range(100))\n",
        "\n",
        "# test = ds_s.map(generate_splits, batched=True, remove_columns = ['text','hits'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7131a3a6-49d4-4a28-8819-09193d0390a3",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "006d44dbeacb44d199e40a954eb9bb9c"
          ]
        },
        "id": "7131a3a6-49d4-4a28-8819-09193d0390a3",
        "outputId": "c55e3811-2f8c-4495-adac-91ba323aaa98"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "006d44dbeacb44d199e40a954eb9bb9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (14716 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "ds_m = ds.select(range(2000))\n",
        "ds_m = ds_m.map(generate_splits, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d389455-9011-4cf2-ba56-cdbd91b5dbbe",
      "metadata": {
        "id": "8d389455-9011-4cf2-ba56-cdbd91b5dbbe",
        "outputId": "f4b53b06-ade8-4897-9fc3-e5bb6c082df0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'hits', 'offset_list'],\n",
              "    num_rows: 2000\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3650ec4-32db-49d1-af0b-8d27e135e451",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "7246fedc264d45959844742e00a7f483"
          ]
        },
        "id": "c3650ec4-32db-49d1-af0b-8d27e135e451",
        "outputId": "4bad5d89-1a79-4833-eeeb-8cc4e6f4a246"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7246fedc264d45959844742e00a7f483",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ds_sentences = ds_m.map(generate_sentences, batched=True, remove_columns = ds_m.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "315d6485-2057-4e4b-8fe7-1681a5c21ec0",
      "metadata": {
        "id": "315d6485-2057-4e4b-8fe7-1681a5c21ec0",
        "outputId": "fe828752-09ec-4731-a6cb-abdd22ad9608"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 91516\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67869c01-59f2-4bb3-b759-81b28ec61fa6",
      "metadata": {
        "id": "67869c01-59f2-4bb3-b759-81b28ec61fa6",
        "outputId": "1d1a96bc-dd6f-4c23-c6d1-f6ed61a6b7f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-18 04:47:48 - Use pytorch device_name: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Set the log level to INFO to get more information\n",
        "logging.basicConfig(format=\"%(asctime)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\", level=logging.INFO, stream=sys.stdout)\n",
        "\n",
        "# Training parameters\n",
        "model_name = model_checkpoint\n",
        "train_batch_size = 4\n",
        "num_epochs = 1\n",
        "max_seq_length = tokenizer.model_max_length\n",
        "\n",
        "output_dir = f\"./output/training_tsdae-{model_name.replace('/', '-')}-{train_batch_size}-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
        "\n",
        "# 1. Defining our sentence transformer model\n",
        "word_embedding_model = models.Transformer(model_name, max_seq_length=max_seq_length)\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), \"cls\")\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
        "# or to load a pre-trained SentenceTransformer model OR use mean pooling\n",
        "# model = SentenceTransformer(model_name)\n",
        "# model.max_seq_length = max_seq_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1857517-9c4c-4dd5-a57c-2e7a117ceeee",
      "metadata": {
        "id": "b1857517-9c4c-4dd5-a57c-2e7a117ceeee",
        "outputId": "7fc929a7-2550-46a2-edd4-ef06fd370ea5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 81516\n",
            "})\n",
            "{'noisy': \"Highway motorists enter the outskirts legal speed limit drops a short from 55 mph to mph leading some drivers who are alert to . fine the posted speed even mph is 146 . Initially used enforcement for construction zones only on books to throughout . red light program and planning put school . Some suburbs . Alsip) have cameras intersections . Some red-light speed limit enforcement cameras (radar') have now approved or are implementation of speed enforcement cameras . The Maryland legislature such program in January 2006 . In 2005, 2006, 2008 2009 the California legislature considered did pass, to implement limit enforcement cameras . legislators considering expanding their speed limit enforcement cameras successes such as 158,811 in revenue three months . 2007 study of speed on the State 101 in Scottsdale found 50 reduction in total crash frequency injuries falling% rear-end increased by As of late, cameras placed along all Phoenix freeways drivers greater than 11 mph over the posted limit . Over 100 new cameras expected be and running 2009 . of, speed in 48 communities the States, including in, Colorado Illinois Iowa Louisiana, Maryland,, New Ohio, Oregon Tennessee,,, D.C . 2017 Council graded states road measures as automated enforcement of speeding red light cameras, interstate speed limits lower speed limits . the United it for, operation and verification be carried companies in some States based the number they and often under testing regime whatsoever, units are to at two pictures each . Opposition groups formed in automated has been used In US city of Scottsdale Arizona an activist group was formed and staged sign-wave and petition drives oppose the limit\", 'text': \" Highway 82 where motorists enter the city's outskirts. The legal speed limit drops in a short space from 55\\xa0mph to 30\\xa0mph, leading to some drivers who are not alert to be caught. The minimum fine for exceeding the posted speed limit even by 1\\xa0mph is $146.\\n\\nInitially, Illinois used photo enforcement for construction zones only.  There was legislation on the books to expand that throughout the state. However, Chicago has expanded its red light camera program and is planning to put speed cameras in school zones. Some suburbs (e.g. Alsip) already have cameras at various intersections.\\n\\nSome U.S. states that formerly allowed red-light enforcement cameras but not speed limit enforcement cameras ('photo radar'), have now approved, or are considering, the implementation of speed limit enforcement cameras. The Maryland legislature approved such a program in January 2006. In 2005, 2006, 2008 and 2009 the California legislature considered, but did not pass, bills to implement speed limit enforcement cameras. Tennessee legislators are also considering expanding their speed limit enforcement cameras after successes in Chattanooga such as generating $158,811 in revenue in the first three months.\\n\\nA 2007 study of speed cameras on the Arizona State Route 101 in Scottsdale found a 50% reduction in the total crash frequency, with injuries falling by 40% however rear-end collisions increased by 55%.\\n\\nAs of late 2008, cameras were placed along all Phoenix area freeways capturing drivers doing speeds greater than 11\\xa0mph over the posted speed limit. Over 100 new cameras were expected to be up and running by 2009.\\n\\nAs of 2009, speed cameras existed in 48 communities in the United States, including in Arizona, Colorado, Illinois, Iowa, Louisiana, Maryland, Massachusetts, New Mexico, Ohio, Oregon, Tennessee, Washington, and Washington, D.C.\\n\\nIn 2017, the National Safety Council graded states on road safety measures such as automated enforcement of speeding or red light cameras, interstate speed limits, and lower speed limits in school zones.\\n\\nIn the United States, it is common for all installation, operation, and verification procedures to be carried out by private companies that in some States receive payment based on the number of infringements they issue, and often under no testing regime whatsoever, however these units are required by law to take at least two pictures of each vehicle.\\n\\nOpposition groups have formed in some locations where automated traffic enforcement has been used.  In the US city of Scottsdale Arizona, an activist group CameraFraud was formed and staged sign-wave protests and petition drives to oppose the use of speed limit\"}\n"
          ]
        }
      ],
      "source": [
        "# Create a dataset from the sentences\n",
        "dataset = ds_sentences\n",
        "\n",
        "\n",
        "def noise_transform(batch, del_ratio=0.6):\n",
        "    \"\"\"\n",
        "    Applies noise by randomly deleting words.\n",
        "\n",
        "    WARNING: nltk's tokenization/detokenization is designed primarily for English.\n",
        "    For other languages, especially those without clear word boundaries (e.g., Chinese),\n",
        "    custom tokenization and detokenization are strongly recommended.\n",
        "\n",
        "    Args:\n",
        "        batch (Dict[str, List[str]]): A dictionary with the structure\n",
        "            {column_name: [string1, string2, ...]}, where each list contains\n",
        "            the batch data for the respective column.\n",
        "        del_ratio (float): The ratio of words to delete. Defaults to 0.6.\n",
        "    \"\"\"\n",
        "    from nltk import word_tokenize\n",
        "    from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "    assert 0.0 <= del_ratio < 1.0, \"del_ratio must be in the range [0, 1)\"\n",
        "    assert isinstance(batch, dict) and \"text\" in batch, \"batch must be a dictionary with a 'text' key.\"\n",
        "\n",
        "    noisy_texts = []\n",
        "    for text in batch[\"text\"]:\n",
        "        words = word_tokenize(text)\n",
        "        n = len(words)\n",
        "        if n == 0:\n",
        "            noisy_texts.append(text)\n",
        "            continue\n",
        "\n",
        "        kept_words = [word for word in words if random.random() < del_ratio]\n",
        "        # Guarantee that at least one word remains\n",
        "        if len(kept_words) == 0:\n",
        "            noisy_texts.append(random.choice(words))\n",
        "            continue\n",
        "\n",
        "        noisy_texts.append(TreebankWordDetokenizer().detokenize(kept_words))\n",
        "    return {\"noisy\": noisy_texts, \"text\": batch[\"text\"]}\n",
        "\n",
        "\n",
        "# TSDAE requires a dataset with 2 columns: a noisified text column and a text column\n",
        "# We use a function to delete some words, but you can customize `noise_transform` to noisify your text some other way.\n",
        "# We use `set_transform` instead of `map` so the noisified text differs each epoch.\n",
        "dataset.set_transform(transform=lambda batch: noise_transform(batch), columns=[\"text\"], output_all_columns=True)\n",
        "dataset = dataset.train_test_split(test_size=10000)\n",
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"test\"]\n",
        "print(train_dataset)\n",
        "print(train_dataset[0])\n",
        "# \"\"\"\n",
        "# Dataset({\n",
        "#     features: ['text'],\n",
        "#     num_rows: 990000\n",
        "# })\n",
        "# {\n",
        "#     'noisy': 'to be the primary antiviral drug used combat influenza commonly as the bird flu.',\n",
        "#     'text': 'Oseltamivir is considered to be the primary antiviral drug used to combat avian influenza, commonly known as the bird flu.',\n",
        "# }\n",
        "# \"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b43ec9cb-391c-46ea-ad08-245c6b0e84d9",
      "metadata": {
        "id": "b43ec9cb-391c-46ea-ad08-245c6b0e84d9",
        "outputId": "002e950a-3cff-426e-e0bb-9758992f3fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-18 04:48:12 - When tie_encoder_decoder=True, the decoder_name_or_path will be invalid.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-18 04:48:14 - Evaluation before training:\n",
            "2025-07-18 04:48:14 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset:\n",
            "2025-07-18 04:48:52 - Cosine-Similarity:\tPearson: 0.2916\tSpearman: 0.3173\n",
            "Evaluation results: {'sts-dev_pearson_cosine': 0.2915711158741553, 'sts-dev_spearman_cosine': 0.3173135052190934}\n"
          ]
        }
      ],
      "source": [
        "# As you can see, the noisy text is applied on the fly when the sample is accessed.\n",
        "\n",
        "# 3. Define our training loss: https://sbert.net/docs/package_reference/sentence_transformer/losses.html#denoisingautoencoderLoss\n",
        "# Note that this will likely result in warnings as we're loading 'model_name' as a decoder, but it likely won't\n",
        "# have weights for that yet. This is fine, as we'll be training it from scratch.\n",
        "train_loss = DenoisingAutoEncoderLoss(model, decoder_name_or_path=model_name, tie_encoder_decoder=True)\n",
        "\n",
        "# 4. Define an evaluator for use during training. This is useful to keep track of alongside the evaluation loss.\n",
        "stsb_eval_dataset = load_dataset(\"sentence-transformers/stsb\", split=\"validation\")\n",
        "dev_evaluator = EmbeddingSimilarityEvaluator(\n",
        "    sentences1=list(stsb_eval_dataset[\"sentence1\"]),\n",
        "    sentences2=list(stsb_eval_dataset[\"sentence2\"]),\n",
        "    scores=list(stsb_eval_dataset[\"score\"]),\n",
        "    main_similarity=SimilarityFunction.COSINE,\n",
        "    name=\"sts-dev\",\n",
        ")\n",
        "logging.info(\"Evaluation before training:\")\n",
        "eval_result = dev_evaluator(model)\n",
        "print(f\"Evaluation results: {eval_result}\")\n",
        "\n",
        "\n",
        "# 5. Define the training arguments\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    # Required parameter:\n",
        "    output_dir=output_dir,\n",
        "    # Optional training parameters:\n",
        "    learning_rate=3e-5,\n",
        "    num_train_epochs=num_epochs,\n",
        "    per_device_train_batch_size=train_batch_size,\n",
        "    per_device_eval_batch_size=train_batch_size,\n",
        "    warmup_ratio=0.1,\n",
        "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
        "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
        "    # Optional tracking/debugging parameters:\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=1000,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=100,\n",
        "    run_name=None,  # Will be used in W&B if `wandb` is installed\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ace44a5-4c39-491b-9c72-8938c2a19299",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "e934f45f91354f71999010c2f8c89714"
          ]
        },
        "id": "1ace44a5-4c39-491b-9c72-8938c2a19299",
        "outputId": "f6d19dac-74ac-4dfe-8625-343c7704f31f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e934f45f91354f71999010c2f8c89714",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20379' max='20379' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20379/20379 6:42:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Sts-dev Pearson Cosine</th>\n",
              "      <th>Sts-dev Spearman Cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.505400</td>\n",
              "      <td>4.501888</td>\n",
              "      <td>0.288322</td>\n",
              "      <td>0.322025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>4.118000</td>\n",
              "      <td>4.148431</td>\n",
              "      <td>0.287340</td>\n",
              "      <td>0.343915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>4.002000</td>\n",
              "      <td>3.980737</td>\n",
              "      <td>0.300894</td>\n",
              "      <td>0.365024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>3.943100</td>\n",
              "      <td>3.879455</td>\n",
              "      <td>0.323986</td>\n",
              "      <td>0.403542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>3.771200</td>\n",
              "      <td>3.802709</td>\n",
              "      <td>0.390993</td>\n",
              "      <td>0.465541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>3.792300</td>\n",
              "      <td>3.745499</td>\n",
              "      <td>0.444961</td>\n",
              "      <td>0.504401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>3.695700</td>\n",
              "      <td>3.697093</td>\n",
              "      <td>0.475574</td>\n",
              "      <td>0.537404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>3.632900</td>\n",
              "      <td>3.660428</td>\n",
              "      <td>0.534822</td>\n",
              "      <td>0.578038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>3.631700</td>\n",
              "      <td>3.626774</td>\n",
              "      <td>0.523794</td>\n",
              "      <td>0.557595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>3.634400</td>\n",
              "      <td>3.600181</td>\n",
              "      <td>0.526074</td>\n",
              "      <td>0.553342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>3.593200</td>\n",
              "      <td>3.573377</td>\n",
              "      <td>0.546522</td>\n",
              "      <td>0.574672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>3.570900</td>\n",
              "      <td>3.551475</td>\n",
              "      <td>0.463718</td>\n",
              "      <td>0.553752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>3.508000</td>\n",
              "      <td>3.532472</td>\n",
              "      <td>0.543415</td>\n",
              "      <td>0.572140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>3.502200</td>\n",
              "      <td>3.515341</td>\n",
              "      <td>0.536949</td>\n",
              "      <td>0.557306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>3.506600</td>\n",
              "      <td>3.497509</td>\n",
              "      <td>0.560740</td>\n",
              "      <td>0.581999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>3.479100</td>\n",
              "      <td>3.483383</td>\n",
              "      <td>0.558794</td>\n",
              "      <td>0.579537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>3.494200</td>\n",
              "      <td>3.474603</td>\n",
              "      <td>0.552983</td>\n",
              "      <td>0.574708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>3.499700</td>\n",
              "      <td>3.464309</td>\n",
              "      <td>0.561484</td>\n",
              "      <td>0.577654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>3.465800</td>\n",
              "      <td>3.456687</td>\n",
              "      <td>0.553871</td>\n",
              "      <td>0.572122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>3.476800</td>\n",
              "      <td>3.452150</td>\n",
              "      <td>0.559675</td>\n",
              "      <td>0.578160</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-18 05:09:57 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.049070121203199375 after 1000 steps:\n",
            "2025-07-18 05:09:58 - Cosine-Similarity:\tPearson: 0.2883\tSpearman: 0.3220\n",
            "2025-07-18 05:09:58 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-1000\n",
            "2025-07-18 05:09:58 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-1000\n",
            "2025-07-18 05:33:03 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.09814024240639875 after 2000 steps:\n",
            "2025-07-18 05:33:05 - Cosine-Similarity:\tPearson: 0.2873\tSpearman: 0.3439\n",
            "2025-07-18 05:33:05 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-2000\n",
            "2025-07-18 05:33:05 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-2000\n",
            "2025-07-18 05:52:32 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.1472103636095981 after 3000 steps:\n",
            "2025-07-18 05:52:34 - Cosine-Similarity:\tPearson: 0.3009\tSpearman: 0.3650\n",
            "2025-07-18 05:52:34 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-3000\n",
            "2025-07-18 05:52:34 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-3000\n",
            "2025-07-18 06:12:01 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.1962804848127975 after 4000 steps:\n",
            "2025-07-18 06:12:03 - Cosine-Similarity:\tPearson: 0.3240\tSpearman: 0.4035\n",
            "2025-07-18 06:12:03 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-4000\n",
            "2025-07-18 06:12:03 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-4000\n",
            "2025-07-18 06:33:27 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.24535060601599687 after 5000 steps:\n",
            "2025-07-18 06:33:29 - Cosine-Similarity:\tPearson: 0.3910\tSpearman: 0.4655\n",
            "2025-07-18 06:33:29 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-5000\n",
            "2025-07-18 06:33:29 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-5000\n",
            "2025-07-18 06:53:00 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.2944207272191962 after 6000 steps:\n",
            "2025-07-18 06:53:02 - Cosine-Similarity:\tPearson: 0.4450\tSpearman: 0.5044\n",
            "2025-07-18 06:53:02 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-6000\n",
            "2025-07-18 06:53:02 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-6000\n",
            "2025-07-18 07:12:33 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.3434908484223956 after 7000 steps:\n",
            "2025-07-18 07:12:34 - Cosine-Similarity:\tPearson: 0.4756\tSpearman: 0.5374\n",
            "2025-07-18 07:12:34 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-7000\n",
            "2025-07-18 07:12:34 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-7000\n",
            "2025-07-18 07:32:03 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.392560969625595 after 8000 steps:\n",
            "2025-07-18 07:32:05 - Cosine-Similarity:\tPearson: 0.5348\tSpearman: 0.5780\n",
            "2025-07-18 07:32:05 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-8000\n",
            "2025-07-18 07:32:05 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-8000\n",
            "2025-07-18 07:51:34 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.44163109082879437 after 9000 steps:\n",
            "2025-07-18 07:51:35 - Cosine-Similarity:\tPearson: 0.5238\tSpearman: 0.5576\n",
            "2025-07-18 07:51:35 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-9000\n",
            "2025-07-18 07:51:35 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-9000\n",
            "2025-07-18 08:11:05 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.49070121203199374 after 10000 steps:\n",
            "2025-07-18 08:11:06 - Cosine-Similarity:\tPearson: 0.5261\tSpearman: 0.5533\n",
            "2025-07-18 08:11:06 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-10000\n",
            "2025-07-18 08:11:06 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-10000\n",
            "2025-07-18 08:30:36 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.5397713332351931 after 11000 steps:\n",
            "2025-07-18 08:30:38 - Cosine-Similarity:\tPearson: 0.5465\tSpearman: 0.5747\n",
            "2025-07-18 08:30:38 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-11000\n",
            "2025-07-18 08:30:38 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-11000\n",
            "2025-07-18 08:50:09 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.5888414544383924 after 12000 steps:\n",
            "2025-07-18 08:50:11 - Cosine-Similarity:\tPearson: 0.4637\tSpearman: 0.5538\n",
            "2025-07-18 08:50:11 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-12000\n",
            "2025-07-18 08:50:11 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-12000\n",
            "2025-07-18 09:09:41 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.6379115756415918 after 13000 steps:\n",
            "2025-07-18 09:09:43 - Cosine-Similarity:\tPearson: 0.5434\tSpearman: 0.5721\n",
            "2025-07-18 09:09:43 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-13000\n",
            "2025-07-18 09:09:43 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-13000\n",
            "2025-07-18 09:29:13 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.6869816968447912 after 14000 steps:\n",
            "2025-07-18 09:29:15 - Cosine-Similarity:\tPearson: 0.5369\tSpearman: 0.5573\n",
            "2025-07-18 09:29:15 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-14000\n",
            "2025-07-18 09:29:15 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-14000\n",
            "2025-07-18 09:48:45 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.7360518180479906 after 15000 steps:\n",
            "2025-07-18 09:48:47 - Cosine-Similarity:\tPearson: 0.5607\tSpearman: 0.5820\n",
            "2025-07-18 09:48:47 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-15000\n",
            "2025-07-18 09:48:47 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-15000\n",
            "2025-07-18 10:08:17 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.78512193925119 after 16000 steps:\n",
            "2025-07-18 10:08:18 - Cosine-Similarity:\tPearson: 0.5588\tSpearman: 0.5795\n",
            "2025-07-18 10:08:18 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-16000\n",
            "2025-07-18 10:08:18 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-16000\n",
            "2025-07-18 10:27:49 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.8341920604543893 after 17000 steps:\n",
            "2025-07-18 10:27:51 - Cosine-Similarity:\tPearson: 0.5530\tSpearman: 0.5747\n",
            "2025-07-18 10:27:51 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-17000\n",
            "2025-07-18 10:27:51 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-17000\n",
            "2025-07-18 10:48:41 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.8832621816575887 after 18000 steps:\n",
            "2025-07-18 10:48:43 - Cosine-Similarity:\tPearson: 0.5615\tSpearman: 0.5777\n",
            "2025-07-18 10:48:44 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-18000\n",
            "2025-07-18 10:48:44 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-18000\n",
            "2025-07-18 11:10:24 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.932332302860788 after 19000 steps:\n",
            "2025-07-18 11:10:27 - Cosine-Similarity:\tPearson: 0.5539\tSpearman: 0.5721\n",
            "2025-07-18 11:10:27 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-19000\n",
            "2025-07-18 11:10:27 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-19000\n",
            "2025-07-18 11:28:50 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset in epoch 0.9814024240639875 after 20000 steps:\n",
            "2025-07-18 11:28:53 - Cosine-Similarity:\tPearson: 0.5597\tSpearman: 0.5782\n",
            "2025-07-18 11:28:53 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-20000\n",
            "2025-07-18 11:28:53 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-20000\n",
            "2025-07-18 11:33:01 - Saving model checkpoint to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-20379\n",
            "2025-07-18 11:33:01 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/checkpoint-20379\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 6. Create the trainer & start training\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    loss=train_loss,\n",
        "    evaluator=dev_evaluator,\n",
        ")\n",
        "trainer.train()\n",
        "#trainer.train(resume_from_checkpoint = True)\n",
        "\n",
        "# 7. Evaluate the model performance on the STS Benchmark test dataset\n",
        "test_dataset = load_dataset(\"sentence-transformers/stsb\", split=\"test\")\n",
        "test_evaluator = EmbeddingSimilarityEvaluator(\n",
        "    sentences1=list(test_dataset[\"sentence1\"]),\n",
        "    sentences2=list(test_dataset[\"sentence2\"]),\n",
        "    scores=list(test_dataset[\"score\"]),\n",
        "    main_similarity=SimilarityFunction.COSINE,\n",
        "    name=\"sts-test\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72c9b6de-88f4-4c50-bd4f-efcd2b65f423",
      "metadata": {
        "id": "72c9b6de-88f4-4c50-bd4f-efcd2b65f423",
        "outputId": "582e9557-68a4-40eb-e149-abe497a12d6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-18 11:44:39 - EmbeddingSimilarityEvaluator: Evaluating the model on the sts-test dataset:\n",
            "2025-07-18 11:44:41 - Cosine-Similarity:\tPearson: 0.4154\tSpearman: 0.4684\n",
            "Evaluation results: {'sts-dev_pearson_cosine': 0.2915711158741553, 'sts-dev_spearman_cosine': 0.3173135052190934}\n",
            "2025-07-18 11:44:41 - Save model to ./output/training_tsdae-bert-base-uncased-4-2025-07-18_04-47-46/final\n"
          ]
        }
      ],
      "source": [
        "eval_results = test_evaluator(model)\n",
        "print(f\"Evaluation results: {eval_result}\")\n",
        "\n",
        "# 8. Save the trained & evaluated model locally\n",
        "final_output_dir = f\"{output_dir}/final\"\n",
        "model.save(final_output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0202016a-5a1e-402a-84b7-e3a196cd43a0",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a3bc0e5366d14d61a44eac8581814f71"
          ]
        },
        "id": "0202016a-5a1e-402a-84b7-e3a196cd43a0",
        "outputId": "a0d47490-d987-471b-b2ff-719d2a109202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-18 11:51:59 - Save model to /tmp/tmp_oizrb20\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3bc0e5366d14d61a44eac8581814f71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/UmarAzam/bert-base-uncased-industrialtech/commit/11a319395c1d71c892c65f1ad24b631c581c0718'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name = model_checkpoint\n",
        "model.push_to_hub(f\"{model_name}-industrialtech\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b78c55e-13cf-4f4e-9ab5-f2673eb4a082",
      "metadata": {
        "id": "8b78c55e-13cf-4f4e-9ab5-f2673eb4a082"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}